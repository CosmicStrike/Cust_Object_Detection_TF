{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Images for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Victory\",\"ThumbsUp\",\"ThumbsDown\"]\n",
    "paths_train = {            \n",
    "            \"Victory\":\"D:\\\\CODE_Club\\\\Custom_ObjD_2\\\\ProjectFiles\\\\Images\\\\Victory\\\\\",            \n",
    "            \"ThumbsUp\": \"D:\\\\CODE_Club\\\\Custom_ObjD_2\\\\ProjectFiles\\\\Images\\\\ThumbsUp\\\\\",            \n",
    "            \"ThumbsDown\": \"D:\\\\CODE_Club\\\\Custom_ObjD_2\\\\ProjectFiles\\\\Images\\\\Thumbs_Down\\\\\"\n",
    "        }\n",
    "paths_test = {\n",
    "            \"Victory\":\"D:\\\\CODE_Club\\\\Custom_ObjD_2\\\\ProjectFiles\\\\Images\\\\Test_Images\\\\\",\n",
    "            \"ThumbsUp\": \"D:\\\\CODE_Club\\\\Custom_ObjD_2\\\\ProjectFiles\\\\Images\\\\Test_Images\\\\\",\n",
    "            \"ThumbsDown\": \"D:\\\\CODE_Club\\\\Custom_ObjD_2\\\\ProjectFiles\\\\Images\\\\Test_Images\\\\\"\n",
    "}\n",
    "\n",
    "path = {\n",
    "    \"labelmap\":\"D:\\\\CODE_Club\\\\Custom_ObjD_2\\\\ProjectFiles\\\\Images\\\\labelmap.pbtxt\",\n",
    "    \"Train_excel_sheet\":\"D:\\\\CODE_Club\\\\Custom_ObjD_2\\\\ProjectFiles\\\\Images\\\\Data.xlsx\",\n",
    "    \"Test_excel_sheet\":\"D:\\\\CODE_Club\\\\Custom_ObjD_2\\\\ProjectFiles\\\\Images\\\\Data1.xlsx\",\n",
    "    \"Train_Tfrecord\":\"D:\\\\CODE_Club\\\\Custom_ObjD_2\\\\ProjectFiles\\\\TfRecords\\\\train.record\",\n",
    "    \"Test_Tfrecord\":\"D:\\\\CODE_Club\\\\Custom_ObjD_2\\\\ProjectFiles\\\\TfRecords\\\\test.record\"\n",
    "}\n",
    "\n",
    "number_of_img_train = 10\n",
    "number_of_img_test = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CaptureImages(Total_Images=None,path=None):\n",
    "    for lab in labels:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        print(\"Collecting Images for \",lab)\n",
    "        time.sleep(8)\n",
    "        print()\n",
    "        for i in range(Total_Images):\n",
    "            print(\"Image no. \",i+1)\n",
    "            isPos, frame = cap.read()\n",
    "            file_name = path[lab]+lab+\"{}.jpg\".format(str(i+1))\n",
    "            print(file_name)\n",
    "            cv2.imshow(\"Webcam\",frame)\n",
    "            cv2.imwrite(file_name,frame)\n",
    "            time.sleep(8)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Traing Set\")\n",
    "print()\n",
    "CaptureImages(number_of_img_train,paths_train)\n",
    "\n",
    "print(\"Testing Set\")\n",
    "print()\n",
    "CaptureImages(number_of_img_test,paths_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create .pbtxt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is taking path and creating labelmap.pbtxt file which is required in tfrecords\n",
    "\n",
    "with open(path[\"labelmap\"], 'w') as lm:\n",
    "    id = 1\n",
    "    for lab in labels:\n",
    "        data = str(\"item { name : \\\"\"+lab+\"\\\" , id : \"+str(id)+\" }\\n\")\n",
    "        lm.write(data)\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting XML to EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # to create csv file\n",
    "import xml.etree.ElementTree as ET # to read the xml file\n",
    "import openpyxl\n",
    "import os # to identify the file using extension\n",
    "# Collecting all xml files path from the given directory\n",
    "\n",
    "\n",
    "def GetAll_XML_FileName(path):\n",
    "    fileName = []\n",
    "\n",
    "    for files in os.listdir(path):\n",
    "        root, ext = os.path.splitext(files)\n",
    "        if ext == \".xml\":\n",
    "            fileName.append(files)\n",
    "\n",
    "    return fileName\n",
    "    \n",
    "\n",
    "# GetAll_XML_FileName(\"D:\\CODE_Club\\Cust_Obj_Detection\\Images\\ThumbsDown\")\n",
    "\n",
    "#features must be in format : filename,filesource,img-width,img-height,img-depth,xmin,ymin,xmax,ymaxs\n",
    "def Extract_Features_XML(path):\n",
    "    features = []\n",
    "    \n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    interF = []\n",
    "\n",
    "    interF.append(root.find('filename').text)\n",
    "    interF.append(root.find('path').text)\n",
    "    imgsize = (root.find('size'))\n",
    "    interF.append(imgsize[0].text)#width\n",
    "    interF.append(imgsize[1].text)#height\n",
    "    interF.append(imgsize[2].text)#depth\n",
    "\n",
    "    for obj in root.findall('object'):\n",
    "        bnd = obj.find('bndbox')\n",
    "        x = []\n",
    "        x.append(bnd[0].text)\n",
    "        x.append(bnd[1].text)\n",
    "        x.append(bnd[2].text)\n",
    "        x.append(bnd[3].text)\n",
    "        features.append(interF+x)\n",
    " \n",
    "    return features\n",
    "\n",
    "\n",
    "def Convert_XML_To_CSV(path,labelName):\n",
    "    all_fileNames = GetAll_XML_FileName(path)\n",
    "    # First create an .csv file to write\n",
    "    header = ['FileName','FileSource','Image-Width','Image-Height','Image-Depth','xmin','ymin','xmax','ymax']\n",
    "\n",
    "    i = 1\n",
    "    workbk = openpyxl.Workbook()\n",
    "    wkbSheet = workbk.active\n",
    "\n",
    "    for data in header:\n",
    "        wkbSheet.cell(1,i).value = data\n",
    "        i = i+ 1\n",
    "\n",
    "    r,c = 2,1\n",
    "    for eachfile in all_fileNames:\n",
    "        Path = path+str(\"\\\\\")+eachfile\n",
    "        xml_features = (Extract_Features_XML(Path))\n",
    "        # print(type(xml_features))\n",
    "        for data in (xml_features):\n",
    "            for d in data:\n",
    "                wkbSheet.cell(r,c).value = d\n",
    "                c = c+ 1\n",
    "            r = r + 1\n",
    "            c = 1\n",
    "        \n",
    "\n",
    "\n",
    "    wbPath = path + str(\"\\\\\")+labelName+str(\".xlsx\")\n",
    "    workbk.save(wbPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function this will convert the all xml files to excel file and store it in path speified where xml files are present\n",
    "\n",
    "# For training \n",
    "Convert_XML_To_CSV(paths_train[\"ThumbsDown\"],\"ThumbsDown\")\n",
    "Convert_XML_To_CSV(paths_train[\"ThumbsUp\"], \"ThumbsUp\")\n",
    "Convert_XML_To_CSV(paths_train[\"Victory\"],\"Victory\")\n",
    "\n",
    "#For testing\n",
    "Convert_XML_To_CSV(paths_test[\"ThumbsDown\"],\"ThumbsDown\")\n",
    "Convert_XML_To_CSV(paths_test[\"ThumbsUp\"], \"ThumbsUp\")\n",
    "Convert_XML_To_CSV(paths_test[\"Victory\"],\"Victory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting XML to Tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelId(labs):\n",
    "    j = 1\n",
    "    for i in labels:\n",
    "        if i == labs:\n",
    "            return j\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "def TF_Record_Creation(gp,fn):\n",
    "    filename = fn.encode('utf8')\n",
    "    fileType = \"jpg\".encode('utf8')\n",
    "    img_Path = []\n",
    "    class_Text = []\n",
    "    class_LbMp = []\n",
    "    width = [640]\n",
    "    height = [480]\n",
    "    minX = []\n",
    "    minY = []\n",
    "    maxX = []\n",
    "    maxY = []\n",
    "\n",
    "    for i, j in gp.iterrows():\n",
    "        minX.append(j['xmin'] / width[0])\n",
    "        maxX.append(j['xmax'] / width[0])\n",
    "        minY.append(j['ymin'] / height[0])\n",
    "        maxY.append(j['ymax'] / height[0])\n",
    "        class_Text.append(j['label'].encode('utf8'))\n",
    "        class_LbMp.append(labelId(j['label']))\n",
    "        img_Path.append(j['FileSource'])\n",
    "\n",
    "    with tf.io.gfile.GFile(img_Path[0],'rb') as fi:\n",
    "        img = fi.read()\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': tf.train.Feature(int64_list = tf.train.Int64List(value=height)),\n",
    "        'image/width': tf.train.Feature(int64_list= tf.train.Int64List(value=width)),\n",
    "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename])),\n",
    "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename])),\n",
    "        # here we give image as input\n",
    "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img])),\n",
    "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[fileType])),\n",
    "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=minX)),\n",
    "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=maxX)),\n",
    "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=minY)),\n",
    "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=maxY)),\n",
    "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=class_Text)),\n",
    "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=class_LbMp)),\n",
    "    }))\n",
    "    return tf_example\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_TfRecords(Excel_Sheet=str,tf_Type=str):\n",
    "    df = pd.read_excel(Excel_Sheet)\n",
    "    gk = df.groupby(\"FileName\")\n",
    "    with tf.io.TFRecordWriter(tf_Type) as file:\n",
    "        for group_name in gk.groups:\n",
    "            datafr = gk.get_group(group_name)\n",
    "            tfRecord = TF_Record_Creation(datafr,group_name)\n",
    "            SerTF_Record = tfRecord.SerializeToString()\n",
    "            file.write(SerTF_Record)\n",
    "        file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Training \n",
    "Generate_TfRecords(path[\"Train_excel_sheet\"],path[\"Train_Tfrecord\"])\n",
    "Generate_TfRecords(path[\"Test_excel_sheet\"],path[\"Test_Tfrecord\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2f807e1519cf520d387b7793850d9faab178050676a34a0cec0470221c29f6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
